{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D,BatchNormalization,Dense,Flatten\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                327690    \n",
      "=================================================================\n",
      "Total params: 328,714\n",
      "Trainable params: 328,650\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=models.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding='same',input_shape=(32,32,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.summary()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 35s 703us/step - loss: 2.4091 - acc: 0.4643\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 1.1482 - acc: 0.6327\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 0.8380 - acc: 0.7165\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 35s 701us/step - loss: 0.6718 - acc: 0.7696\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 35s 692us/step - loss: 0.5453 - acc: 0.8134\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 35s 694us/step - loss: 0.4714 - acc: 0.8392\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 35s 698us/step - loss: 0.4044 - acc: 0.8608\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 35s 694us/step - loss: 0.3579 - acc: 0.8782\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.3185 - acc: 0.8905\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.2754 - acc: 0.9058\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.2678 - acc: 0.9079\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 35s 707us/step - loss: 0.2424 - acc: 0.9205\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 35s 698us/step - loss: 0.2115 - acc: 0.9285\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 0.1882 - acc: 0.9378\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.1773 - acc: 0.9412\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.1743 - acc: 0.9429\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.1805 - acc: 0.9415\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 35s 697us/step - loss: 0.1579 - acc: 0.9502\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 35s 694us/step - loss: 0.1542 - acc: 0.9496\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.1260 - acc: 0.9610\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.1096 - acc: 0.9661\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 35s 694us/step - loss: 0.1215 - acc: 0.9615\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.1284 - acc: 0.9592\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 35s 697us/step - loss: 0.1227 - acc: 0.9620\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 35s 694us/step - loss: 0.1143 - acc: 0.9650\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 35s 694us/step - loss: 0.1119 - acc: 0.9652\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 35s 698us/step - loss: 0.0975 - acc: 0.9698\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 35s 692us/step - loss: 0.1021 - acc: 0.9683\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 35s 700us/step - loss: 0.0932 - acc: 0.9719\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.0826 - acc: 0.9749\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.0928 - acc: 0.9726\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.0848 - acc: 0.9749\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.0764 - acc: 0.9774\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.0816 - acc: 0.9757\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 35s 705us/step - loss: 0.0819 - acc: 0.9761\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 35s 697us/step - loss: 0.0842 - acc: 0.9743\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.0829 - acc: 0.9754\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 35s 700us/step - loss: 0.0743 - acc: 0.9781\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.0675 - acc: 0.9792\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 35s 697us/step - loss: 0.0636 - acc: 0.9816\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.0791 - acc: 0.9773\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.0706 - acc: 0.9789\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.0548 - acc: 0.9837\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 0.0561 - acc: 0.9847\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.0764 - acc: 0.9781\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 35s 698us/step - loss: 0.0692 - acc: 0.9801\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 35s 703us/step - loss: 0.0646 - acc: 0.9811\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 35s 697us/step - loss: 0.0590 - acc: 0.9822\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 35s 697us/step - loss: 0.0555 - acc: 0.9839\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 35s 698us/step - loss: 0.0509 - acc: 0.9854\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 0.0468 - acc: 0.9867\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 35s 694us/step - loss: 0.0481 - acc: 0.9860\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 35s 694us/step - loss: 0.0682 - acc: 0.9814\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.0676 - acc: 0.9805\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 35s 694us/step - loss: 0.0545 - acc: 0.9846\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.0453 - acc: 0.9870\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 35s 692us/step - loss: 0.0442 - acc: 0.9879\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 35s 698us/step - loss: 0.0644 - acc: 0.9821\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.0579 - acc: 0.9831\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.0384 - acc: 0.9894\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 35s 691us/step - loss: 0.0334 - acc: 0.9901\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.0360 - acc: 0.9888\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 35s 692us/step - loss: 0.0423 - acc: 0.9879\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.0538 - acc: 0.9841\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.0443 - acc: 0.9884\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 35s 704us/step - loss: 0.0427 - acc: 0.9880\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 35s 703us/step - loss: 0.0429 - acc: 0.9877\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 0.0470 - acc: 0.9867\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 35s 701us/step - loss: 0.0518 - acc: 0.9858\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.0422 - acc: 0.9879\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.0365 - acc: 0.9895\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 35s 697us/step - loss: 0.0385 - acc: 0.9898\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 35s 697us/step - loss: 0.0352 - acc: 0.9902\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 0.0452 - acc: 0.9877\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 0.0359 - acc: 0.9898\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 0.0466 - acc: 0.9875\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 35s 698us/step - loss: 0.0448 - acc: 0.98811s - loss: \n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 35s 697us/step - loss: 0.0422 - acc: 0.9888\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.0370 - acc: 0.9901\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 35s 692us/step - loss: 0.0344 - acc: 0.9906\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.0385 - acc: 0.9903\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.0371 - acc: 0.9900\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.0260 - acc: 0.9934\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.0410 - acc: 0.9894\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.0403 - acc: 0.9894\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.0353 - acc: 0.9902\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 35s 694us/step - loss: 0.0314 - acc: 0.9918\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 35s 695us/step - loss: 0.0323 - acc: 0.9913\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 35s 698us/step - loss: 0.0172 - acc: 0.9958\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 35s 702us/step - loss: 0.0288 - acc: 0.9922\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.0495 - acc: 0.9870\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 35s 708us/step - loss: 0.0491 - acc: 0.9869\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 36s 721us/step - loss: 0.0244 - acc: 0.9933\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.0276 - acc: 0.9925\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 35s 701us/step - loss: 0.0305 - acc: 0.9922\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 35s 702us/step - loss: 0.0275 - acc: 0.9925\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 35s 692us/step - loss: 0.0313 - acc: 0.9916\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 0.0240 - acc: 0.9934\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 35s 704us/step - loss: 0.0308 - acc: 0.9919\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 35s 700us/step - loss: 0.0391 - acc: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e911962400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x_train,y_train,batch_size=128,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train=np.mean(x_train)\n",
    "mean_std=np.std(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1215776e-01, 2.4860016e-09, 1.0563685e-01, 4.9868967e-02,\n",
       "        5.3958273e-01, 3.5254587e-03, 4.1027293e-03, 1.8924215e-05,\n",
       "        8.5106611e-02, 6.4013217e-10]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "model.predict(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 元堤ㄇㄨ\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    " Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    " Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHot Label 由(None, 1)-(None, 10)\n",
    "ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D('自己設計參數'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D('自己設計參數'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense('自己設計FC層參數')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='輸出函數應該用什麼？'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
